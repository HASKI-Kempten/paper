{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LPs after Graf with hard limit and no tolerance to interchange\n",
    "compare = [\n",
    "    [\n",
    "        'KÜ LK ZF ÜB AN SE RQ AB ZL BE FO LZ ',\n",
    "        'KÜ LK ZF ÜB SE AN RQ AB ZL BE FO LZ ',\n",
    "        'KÜ LK ZF ÜB AN SE RQ AB BE ZL FO LZ ',\n",
    "        'KÜ LK ZF ÜB SE AN RQ AB BE ZL FO LZ ',\n",
    "        'KÜ LK ZF ÜB RQ SE AN AB BE ZL FO LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK AN BE AB SE ÜB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN BE AB ÜB SE RQ ZF FO ZL LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF AN SE ÜB AB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN SE AB ÜB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB SE AB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB AB SE BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN AB SE ÜB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN AB ÜB SE BE FO RQ ZL LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF BE AB AN SE ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AB AN ÜB SE RQ FO ZL LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF AN SE ÜB AB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB SE AB BE FO RQ ZL LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF AN SE ÜB AB BE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN SE AB ÜB BE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB SE AB BE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB SE ÜB BE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB AB SE BE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB ÜB SE BE RQ FO ZL LZ '\n",
    "    ]\n",
    "]\n",
    "\n",
    "#LPs after Graf with soft limit and tolerance +/-1\n",
    "compare_soft = [ \n",
    "    [\n",
    "        'KÜ LK ZF ÜB RQ AN SE AB ZL BE FO LZ ',\n",
    "        'KÜ LK ZF ÜB AN RQ SE AB ZL BE FO LZ ',\n",
    "        'KÜ LK ZF ÜB RQ SE AN AB ZL BE FO LZ ',\n",
    "        'KÜ LK ZF ÜB SE RQ AN AB ZL BE FO LZ '\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK AN AB BE SE ÜB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN AB BE ÜB SE RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN BE SE AB ÜB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN BE ÜB AB SE RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN BE SE ÜB AB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN BE ÜB SE AB RQ ZF FO ZL LZ '\n",
    "    ],\n",
    "    [\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF BE AB AN RQ SE ÜB FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AB AN RQ ÜB SE FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AB AN SE RQ ÜB FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AB AN ÜB RQ SE FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AN AB RQ SE ÜB FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AN AB RQ ÜB SE FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AN AB SE RQ ÜB FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AN AB ÜB RQ SE FO ZL LZ ',\n",
    "        'KÜ LK ZF BE AB AN RQ SE ÜB ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AB AN RQ ÜB SE ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AB AN SE RQ ÜB ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AB AN ÜB RQ SE ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AN AB RQ SE ÜB ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AN AB RQ ÜB SE ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AN AB SE RQ ÜB ZL FO LZ ',\n",
    "        'KÜ LK ZF BE AN AB ÜB RQ SE ZL FO LZ ',\n",
    "    ],\n",
    "    [\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK ZF AN SE ÜB BE AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN SE AB BE ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB SE BE AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB SE BE ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB AB BE SE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB ÜB BE SE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN SE BE ÜB AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN SE BE AB ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB BE SE AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB BE SE ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB BE AB SE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN AB BE ÜB SE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE SE ÜB AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE SE AB ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE ÜB SE AB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE AB SE ÜB RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE ÜB AB SE RQ FO ZL LZ ',\n",
    "        'KÜ LK ZF AN BE AB ÜB SE RQ FO ZL LZ ',\n",
    "    ]\n",
    "]\n",
    "\n",
    "compare_soft_2 = [\n",
    "    [\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        'KÜ LK AN SE BE AB ÜB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN SE AB BE ÜB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN SE AB ÜB BE RQ ZF FO ZL LZ ',\n",
    "\n",
    "        'KÜ LK AN ÜB BE AB SE RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN ÜB AB BE SE RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN ÜB AB SE BE RQ ZF FO ZL LZ ',\n",
    "\n",
    "        'KÜ LK AN SE BE ÜB AB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN SE ÜB BE AB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN SE ÜB AB BE RQ ZF FO ZL LZ ',\n",
    "\n",
    "        'KÜ LK AN ÜB BE SE AB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN ÜB SE BE AB RQ ZF FO ZL LZ ',\n",
    "        'KÜ LK AN ÜB SE AB BE RQ ZF FO ZL LZ '\n",
    "    ],\n",
    "    [],\n",
    "    [],\n",
    "    [\n",
    "        'KÜ LK ZF AN SE AB ÜB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN ÜB AB SE BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN AB SE ÜB BE FO RQ ZL LZ ',\n",
    "        'KÜ LK ZF AN AB ÜB SE BE FO RQ ZL LZ ',\n",
    "    ],\n",
    "    []\n",
    "]\n",
    "\n",
    "learning_style_list = [\n",
    "    {\"AKT\": 5, \"INT\": 9, \"VIS\": 9, \"GLO\": 9},\n",
    "    {\"REF\": 1, \"SNS\": 7, \"VIS\": 5, \"SEQ\": 5},\n",
    "    {\"AKT\": 3, \"SNS\": 7, \"VIS\": 3, \"GLO\": 3},\n",
    "    {\"REF\": 3, \"SNS\": 7, \"VIS\": 5, \"GLO\": 5},\n",
    "    {\"AKT\": 5, \"SNS\": 7, \"VIS\": 7, \"GLO\": 3},\n",
    "    {\"AKT\": 1, \"SNS\": 7, \"VIS\": 5, \"GLO\": 1}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(position, algo):\n",
    "    print(\"Analysis for Learning Style:\")\n",
    "    print(learning_style_list[position])\n",
    "\n",
    "    if algo == 'ACO':\n",
    "        path = '../DataACO/1Mio/results-' + str(position) + '.json'\n",
    "    else:\n",
    "        path = '../DataGA/1Mio/results-' + str(position) + '.json'\n",
    "    \n",
    "    file = open(path, encoding='utf-8')\n",
    "\n",
    "    data = json.load(file)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    #Nr of different LPs\n",
    "    print(\"Nr. of found LPs: \")\n",
    "    print(len(data['results'][0]['results']))\n",
    "    print()\n",
    "\n",
    "    #Percantage of same as Graf with # noted\n",
    "\n",
    "    count = 0\n",
    "    for path in data['results'][0]['results']:\n",
    "        if path['path'] in compare[position]:\n",
    "            count += path['occurence']\n",
    "    print(str(round((count/1000000)*100,4)) + '% Accuracy with Graf et al. and no tolerance')\n",
    "    \n",
    "    #Percantage of same as Graf with # noted and tolerance +/-1\n",
    "    for path in data['results'][0]['results']:\n",
    "        if path['path'] in compare_soft[position]:\n",
    "            count += path['occurence']\n",
    "    print(str(round((count/1000000)*100,4)) + '% Accuracy with Graf et al. and tolerance +/-1')\n",
    "    \n",
    "    #Percantage of same as Graf with # noted and tolerance +/-2\n",
    "    for path in data['results'][0]['results']:\n",
    "        if path['path'] in compare_soft_2[position]:\n",
    "            count += path['occurence']\n",
    "    print(str(round((count/1000000)*100,4)) + '% Accuracy with Graf et al. and tolerance +/-2')\n",
    "    print()\n",
    "\n",
    "    #Shorttest/Average/Longest LP Cost\n",
    "    print(\"Learning Path costs:\")\n",
    "    costs = []\n",
    "    for ele in data['results'][0]['results']:\n",
    "        for _ in range(ele['occurence']):\n",
    "            costs.append(ele['cost'])\n",
    "\n",
    "    costs.sort()\n",
    "    print('Shortest LP cost: ' + str(costs[0]))\n",
    "    print('Average LP cost: ' + str(statistics.mean(costs)))\n",
    "    print('Median LP cost: ' + str(statistics.median(costs)))\n",
    "    print('Longest LP cost: ' + str(costs[-1]))\n",
    "    print(\"Standard deviation in LP costs: \" + str(statistics.pstdev(costs)))\n",
    "    print(\"Variance in LP costs: \" + str(statistics.variance(costs)))\n",
    "    print()\n",
    "\n",
    "    #Calculation Time\n",
    "    print('Calculation Time for LPs:')\n",
    "    times = data['results'][0]['times']\n",
    "    times.sort()\n",
    "    print('Shortest calculation time: ' + str(times[0]))\n",
    "    print('Average calculation time: ' + str(statistics.mean(times)))\n",
    "    print('Median calculation time: ' + str(statistics.median(times)))\n",
    "    print('Longest calculation time: ' + str(times[-1]))\n",
    "    print(\"Standard deviation in calculation time: \" + str(statistics.pstdev(times)))\n",
    "    print(\"Variance in calculation time: \" + str(statistics.variance(times)))\n",
    "    print('---------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'INT': 9, 'VIS': 9, 'GLO': 9}\n",
      "Nr. of found LPs: \n",
      "77\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 124.81\n",
      "Average LP cost: 125.35991314\n",
      "Median LP cost: 124.81\n",
      "Longest LP cost: 140.87\n",
      "Standard deviation in LP costs: 1.2884078860575712\n",
      "Variance in LP costs: 1.6599965408518804\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8591501712799072\n",
      "Average calculation time: 0.9384846669790745\n",
      "Median calculation time: 0.9372813701629639\n",
      "Longest calculation time: 1.5621342658996582\n",
      "Standard deviation in calculation time: 0.01396738144492607\n",
      "Variance in calculation time: 0.00019508793951600456\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 1, 'SNS': 7, 'VIS': 5, 'SEQ': 5}\n",
      "Nr. of found LPs: \n",
      "49\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 68.72\n",
      "Average LP cost: 68.72290233\n",
      "Median LP cost: 68.72\n",
      "Longest LP cost: 79.3\n",
      "Standard deviation in LP costs: 0.15525830985995923\n",
      "Variance in LP costs: 0.024105166885737994\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8746354579925537\n",
      "Average calculation time: 0.9282502936444282\n",
      "Median calculation time: 0.9372537136077881\n",
      "Longest calculation time: 1.5933771133422852\n",
      "Standard deviation in calculation time: 0.02489416636698035\n",
      "Variance in calculation time: 0.0006197201388270344\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 3, 'SNS': 7, 'VIS': 3, 'GLO': 3}\n",
      "Nr. of found LPs: \n",
      "19\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 72.26\n",
      "Average LP cost: 73.30427110000001\n",
      "Median LP cost: 72.26\n",
      "Longest LP cost: 79.18\n",
      "Standard deviation in LP costs: 1.6715792464327797\n",
      "Variance in LP costs: 2.7941799712847506\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8591475486755371\n",
      "Average calculation time: 0.9082344990344048\n",
      "Median calculation time: 0.9060628414154053\n",
      "Longest calculation time: 1.6090068817138672\n",
      "Standard deviation in calculation time: 0.012733060849734575\n",
      "Variance in calculation time: 0.00016213100073404407\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 3, 'SNS': 7, 'VIS': 5, 'GLO': 5}\n",
      "Nr. of found LPs: \n",
      "10\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 81.14\n",
      "Average LP cost: 82.69173055\n",
      "Median LP cost: 81.98\n",
      "Longest LP cost: 85.71\n",
      "Standard deviation in LP costs: 1.504407898841502\n",
      "Variance in LP costs: 2.2632453893420923\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8559494018554688\n",
      "Average calculation time: 0.9094162646791935\n",
      "Median calculation time: 0.9060397148132324\n",
      "Longest calculation time: 1.655871868133545\n",
      "Standard deviation in calculation time: 0.01867115070689968\n",
      "Variance in calculation time: 0.00034861221733197765\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'SNS': 7, 'VIS': 7, 'GLO': 3}\n",
      "Nr. of found LPs: \n",
      "34\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 83.2\n",
      "Average LP cost: 85.67560631\n",
      "Median LP cost: 84.24\n",
      "Longest LP cost: 94.59\n",
      "Standard deviation in LP costs: 2.552686982218578\n",
      "Variance in LP costs: 6.516217345405536\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8371741771697998\n",
      "Average calculation time: 0.8879819511942864\n",
      "Median calculation time: 0.8904168605804443\n",
      "Longest calculation time: 1.9682786464691162\n",
      "Standard deviation in calculation time: 0.013208168611582156\n",
      "Variance in calculation time: 0.00017445589252787665\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 1, 'SNS': 7, 'VIS': 5, 'GLO': 1}\n",
      "Nr. of found LPs: \n",
      "2\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 66.09\n",
      "Average LP cost: 66.09\n",
      "Median LP cost: 66.09\n",
      "Longest LP cost: 66.09\n",
      "Standard deviation in LP costs: 0.0\n",
      "Variance in LP costs: 0.0\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.8556125164031982\n",
      "Average calculation time: 0.9092306726236343\n",
      "Median calculation time: 0.9060378074645996\n",
      "Longest calculation time: 2.124490976333618\n",
      "Standard deviation in calculation time: 0.03154833740228016\n",
      "Variance in calculation time: 0.0009952985881466977\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'INT': 9, 'VIS': 9, 'GLO': 9}\n",
      "Nr. of found LPs: \n",
      "12\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 124.80516071035446\n",
      "Average LP cost: 129.19546281507704\n",
      "Median LP cost: 128.63201367963978\n",
      "Longest LP cost: 135.1634269144629\n",
      "Standard deviation in LP costs: 3.8744703705151684\n",
      "Variance in LP costs: 15.011535663535609\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.041288137435913086\n",
      "Average calculation time: 0.058368892480373386\n",
      "Median calculation time: 0.05928909778594971\n",
      "Longest calculation time: 1.6524653434753418\n",
      "Standard deviation in calculation time: 0.006876860238287722\n",
      "Variance in calculation time: 4.7291254028196703e-05\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 1, 'SNS': 7, 'VIS': 5, 'SEQ': 5}\n",
      "Nr. of found LPs: \n",
      "8\n",
      "\n",
      "11.7309% Accuracy with Graf et al. and no tolerance\n",
      "11.7309% Accuracy with Graf et al. and tolerance +/-1\n",
      "50.6857% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 68.7237605486853\n",
      "Average LP cost: 69.02818203968914\n",
      "Median LP cost: 69.0809736540925\n",
      "Longest LP cost: 69.46613846122699\n",
      "Standard deviation in LP costs: 0.27820190304365716\n",
      "Variance in LP costs: 0.07739637625348868\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.03776669502258301\n",
      "Average calculation time: 0.05262615780901909\n",
      "Median calculation time: 0.05066800117492676\n",
      "Longest calculation time: 0.8349676132202148\n",
      "Standard deviation in calculation time: 0.005566413892510285\n",
      "Variance in calculation time: 3.098499460772612e-05\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 3, 'SNS': 7, 'VIS': 3, 'GLO': 3}\n",
      "Nr. of found LPs: \n",
      "2\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 72.25838817753541\n",
      "Average LP cost: 72.25838817753541\n",
      "Median LP cost: 72.25838817753541\n",
      "Longest LP cost: 72.25838817753541\n",
      "Standard deviation in LP costs: 0.0\n",
      "Variance in LP costs: 0.0\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.03774905204772949\n",
      "Average calculation time: 0.05337692648744583\n",
      "Median calculation time: 0.050701141357421875\n",
      "Longest calculation time: 0.8147468566894531\n",
      "Standard deviation in calculation time: 0.005693057856211457\n",
      "Variance in calculation time: 3.241094016511116e-05\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 3, 'SNS': 7, 'VIS': 5, 'GLO': 5}\n",
      "Nr. of found LPs: \n",
      "4\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 81.13841545605035\n",
      "Average LP cost: 81.17902216792041\n",
      "Median LP cost: 81.13841545605035\n",
      "Longest LP cost: 81.7912040079362\n",
      "Standard deviation in LP costs: 0.15766639334241087\n",
      "Variance in LP costs: 0.024858716448320266\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.0358738899230957\n",
      "Average calculation time: 0.05665147401213646\n",
      "Median calculation time: 0.0532078742980957\n",
      "Longest calculation time: 0.8366761207580566\n",
      "Standard deviation in calculation time: 0.010246449845098603\n",
      "Variance in calculation time: 0.0001049898394179606\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'SNS': 7, 'VIS': 7, 'GLO': 3}\n",
      "Nr. of found LPs: \n",
      "2\n",
      "\n",
      "0.0% Accuracy with Graf et al. and no tolerance\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "0.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 89.83619093069268\n",
      "Average LP cost: 89.83619093069268\n",
      "Median LP cost: 89.83619093069268\n",
      "Longest LP cost: 89.83619093069268\n",
      "Standard deviation in LP costs: 0.0\n",
      "Variance in LP costs: 0.0\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.03573155403137207\n",
      "Average calculation time: 0.056260416039705274\n",
      "Median calculation time: 0.05315232276916504\n",
      "Longest calculation time: 0.8429248332977295\n",
      "Standard deviation in calculation time: 0.009458955013602416\n",
      "Variance in calculation time: 8.947191942127369e-05\n",
      "---------------------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 1, 'SNS': 7, 'VIS': 5, 'GLO': 1}\n",
      "Nr. of found LPs: \n",
      "4\n",
      "\n",
      "74.9882% Accuracy with Graf et al. and no tolerance\n",
      "100.0% Accuracy with Graf et al. and tolerance +/-1\n",
      "100.0% Accuracy with Graf et al. and tolerance +/-2\n",
      "\n",
      "Learning Path costs:\n",
      "Shortest LP cost: 66.08522035203386\n",
      "Average LP cost: 66.25686824473352\n",
      "Median LP cost: 66.08522035203386\n",
      "Longest LP cost: 66.77148800450057\n",
      "Standard deviation in LP costs: 0.29720934929039927\n",
      "Variance in LP costs: 0.0883334856391082\n",
      "\n",
      "Calculation Time for LPs:\n",
      "Shortest calculation time: 0.034392356872558594\n",
      "Average calculation time: 0.05467110765981674\n",
      "Median calculation time: 0.051520586013793945\n",
      "Longest calculation time: 0.8224813938140869\n",
      "Standard deviation in calculation time: 0.00927887059803553\n",
      "Variance in calculation time: 8.609752567261392e-05\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Analyse the results of the GA\n",
    "for i in range(6):\n",
    "    analyse(i, \"GA\")\n",
    "\n",
    "#Analyse the results of the ACO\n",
    "for i in range(6):\n",
    "    analyse(i, \"ACO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_calculation(position, algo):\n",
    "    print(\"Analysis for Learning Style:\")\n",
    "    print(learning_style_list[position])\n",
    "\n",
    "    if algo == 'ACO':\n",
    "        path = '../DataACO/1Mio/results-' + str(position) + '.json'\n",
    "    else:\n",
    "        path = '../DataGA/1Mio/results-' + str(position) + '.json'\n",
    "    file = open(path, encoding='utf-8')\n",
    "\n",
    "    data = json.load(file)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    nr_of_lps = len(data['results'][0]['results'])\n",
    "    print(\"Total Nr. of LPs found for LS: \" + str(nr_of_lps))\n",
    "    correct_paths = compare[position] + compare_soft[position] + compare_soft_2[position]\n",
    "\n",
    "    problem_les = {}\n",
    "    problem_count = 0\n",
    "    print()\n",
    "    print(\"Problematic LEs, when no difference is allwoed (and percentage of error)\")\n",
    "    #Which LEs do need a further definition of Difference\n",
    "    for path in data['results'][0]['results']:\n",
    "        occurence = path['occurence']\n",
    "        path = path['path'].split(' ')\n",
    "        les = []\n",
    "       \n",
    "        total_problems = 0\n",
    "        for i in range(len(path)-1):\n",
    "            is_valid = False\n",
    "            for lp in correct_paths:\n",
    "                if path[i] in lp.split(' ')[i:i+1]:\n",
    "                    is_valid = True\n",
    "                    break\n",
    "            if not is_valid:\n",
    "                total_problems += 1\n",
    "                les.append(path[i])\n",
    "        if total_problems > 0:\n",
    "            problem_count += occurence\n",
    "        for le in les:\n",
    "            if le in problem_les.keys():\n",
    "                problem_les[le] += (1/total_problems)*occurence\n",
    "            else:\n",
    "                problem_les[le] = (1/total_problems)*occurence\n",
    "\n",
    "    for key in problem_les.keys():\n",
    "        print(\"    \" + key + \": \" + str(round((problem_les[key]/problem_count)*100,2)) + \"%\")\n",
    "    print()\n",
    "    \n",
    "    #Difference +/-1\n",
    "    print(\"LPs with Difference +/-1 allowed\")\n",
    "    count_1 = 0\n",
    "    problem_count = 0\n",
    "    problem_les = {}\n",
    "    for path in data['results'][0]['results']:\n",
    "        occurence = path['occurence']\n",
    "        path = path['path'].split(' ')\n",
    "        wrong_les = []\n",
    "        total_problems = 0\n",
    "        for i in range(len(path)-1):\n",
    "\n",
    "            is_valid = False\n",
    "            for lp in correct_paths:\n",
    "                min = 0 if i-1 < 0 else i-1\n",
    "                max = len(lp.split(' '))-1 if i+2 > len(lp.split(' '))-1 else i+2\n",
    "                if path[i] in lp.split(' ')[min:max]:\n",
    "                    is_valid = True\n",
    "                if is_valid:\n",
    "                    break\n",
    "            if not is_valid:\n",
    "                wrong_les.append(path[i])\n",
    "                total_problems += 1\n",
    "            \n",
    "        if total_problems > 0:\n",
    "            problem_count += occurence\n",
    "        for le in wrong_les:\n",
    "            if le in problem_les.keys():\n",
    "                problem_les[le] += (1/total_problems)*occurence\n",
    "            else:\n",
    "                problem_les[le] = (1/total_problems)*occurence\n",
    "\n",
    "        if len(wrong_les) == 0:\n",
    "            count_1 += occurence\n",
    "\n",
    "    print('Accuracy: ' + str((count_1/1000000)*100) + '%')\n",
    "    print(\"Problematic LEs (and percentage of error)\")\n",
    "    for key in problem_les.keys():\n",
    "        print(\"    \" + key + \": \" + str(round((problem_les[key]/problem_count)*100,2)) + \"%\")\n",
    "    if not problem_les:\n",
    "        print(\"    -/-\")\n",
    "    print()\n",
    "\n",
    "    #Difference  +/-2\n",
    "    print(\"LPs with Difference +/-2 allowed\")\n",
    "    count_2 = 0\n",
    "    problem_count = 0\n",
    "    problem_les = {}\n",
    "    for path in data['results'][0]['results']:\n",
    "        occurence = path['occurence']\n",
    "        path = path['path'].split(' ')\n",
    "        wrong_les = []\n",
    "        total_problems = 0\n",
    "        for i in range(len(path)-1):\n",
    "\n",
    "            is_valid = False\n",
    "            for lp in correct_paths:\n",
    "                min = 0 if i-2 < 0 else i-2\n",
    "                max = len(lp.split(' '))-1 if i+3 > len(lp.split(' '))-1 else i+3\n",
    "                if path[i] in lp.split(' ')[min:max]:\n",
    "                    is_valid = True\n",
    "                if is_valid:\n",
    "                    break\n",
    "            if not is_valid:\n",
    "                wrong_les.append(path[i])\n",
    "                total_problems += 1\n",
    "\n",
    "        if total_problems > 0:\n",
    "            problem_count += occurence\n",
    "        for le in wrong_les:\n",
    "            if le in problem_les.keys():\n",
    "                problem_les[le] += (1/total_problems)*occurence\n",
    "            else:\n",
    "                problem_les[le] = (1/total_problems)*occurence\n",
    "\n",
    "        if len(wrong_les) == 0:\n",
    "            count_2 += occurence\n",
    "\n",
    "    print('Accuracy: ' + str((count_2/1000000)*100) + '%')\n",
    "    print(\"Problematic LEs (and percentage of error)\")\n",
    "    for key in problem_les.keys():\n",
    "        print(\"    \" + key + \": \" + str(round((problem_les[key]/problem_count)*100,2)) + \"%\")\n",
    "    if not problem_les:\n",
    "        print(\"    -/-\")\n",
    "    print()\n",
    "    print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'INT': 9, 'VIS': 9, 'GLO': 9}\n",
      "Total Nr. of LPs found for LS: 77\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    ZL: 24.25%\n",
      "    ÜB: 24.45%\n",
      "    FO: 24.45%\n",
      "    SE: 24.14%\n",
      "    AB: 0.86%\n",
      "    BE: 0.75%\n",
      "    AN: 0.71%\n",
      "    RQ: 0.39%\n",
      "    ZF: 0.0%\n",
      "    LK: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 34.37%\n",
      "    ÜB: 11.58%\n",
      "    FO: 17.69%\n",
      "    SE: 34.02%\n",
      "    AB: 0.41%\n",
      "    BE: 0.87%\n",
      "    RQ: 0.41%\n",
      "    AN: 0.65%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 48.4%\n",
      "    SE: 48.01%\n",
      "    AB: 0.36%\n",
      "    BE: 0.3%\n",
      "    FO: 1.21%\n",
      "    ÜB: 0.52%\n",
      "    RQ: 0.45%\n",
      "    AN: 0.76%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 1, 'SNS': 7, 'VIS': 5, 'SEQ': 5}\n",
      "Total Nr. of LPs found for LS: 49\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.29%\n",
      "    ZL: 14.29%\n",
      "    AN: 14.29%\n",
      "    FO: 14.29%\n",
      "    ÜB: 14.28%\n",
      "    SE: 14.29%\n",
      "    RQ: 14.29%\n",
      "    ZF: 0.01%\n",
      "    BE: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 22.49%\n",
      "    AN: 10.03%\n",
      "    FO: 22.49%\n",
      "    SE: 22.49%\n",
      "    RQ: 22.49%\n",
      "    ZF: 0.0%\n",
      "    ÜB: 0.0%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 24.99%\n",
      "    FO: 25.0%\n",
      "    SE: 25.0%\n",
      "    RQ: 25.0%\n",
      "    ZF: 0.01%\n",
      "    AN: 0.01%\n",
      "    ÜB: 0.0%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 3, 'SNS': 7, 'VIS': 3, 'GLO': 3}\n",
      "Total Nr. of LPs found for LS: 19\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 13.74%\n",
      "    AN: 13.74%\n",
      "    ZL: 13.74%\n",
      "    FO: 13.74%\n",
      "    ÜB: 13.74%\n",
      "    SE: 13.74%\n",
      "    RQ: 13.74%\n",
      "    BE: 3.84%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 21.34%\n",
      "    FO: 20.74%\n",
      "    ÜB: 21.34%\n",
      "    SE: 21.34%\n",
      "    AN: 11.59%\n",
      "    BE: 3.65%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 42.77%\n",
      "    SE: 34.66%\n",
      "    BE: 2.15%\n",
      "    FO: 6.62%\n",
      "    AN: 5.68%\n",
      "    ÜB: 8.12%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 3, 'SNS': 7, 'VIS': 5, 'GLO': 5}\n",
      "Total Nr. of LPs found for LS: 10\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    FO: 19.01%\n",
      "    ZL: 19.01%\n",
      "    AB: 10.87%\n",
      "    AN: 13.08%\n",
      "    ÜB: 15.02%\n",
      "    RQ: 19.01%\n",
      "    SE: 3.99%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    FO: 28.47%\n",
      "    ZL: 28.47%\n",
      "    AN: 10.42%\n",
      "    RQ: 22.88%\n",
      "    AB: 4.17%\n",
      "    SE: 5.59%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    FO: 70.81%\n",
      "    ZL: 29.19%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'SNS': 7, 'VIS': 7, 'GLO': 3}\n",
      "Total Nr. of LPs found for LS: 34\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.25%\n",
      "    ZL: 14.25%\n",
      "    AN: 14.25%\n",
      "    FO: 14.24%\n",
      "    ÜB: 13.66%\n",
      "    SE: 4.72%\n",
      "    RQ: 14.25%\n",
      "    BE: 10.38%\n",
      "    ZF: 0.0%\n",
      "    LK: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 35.25%\n",
      "    AN: 15.03%\n",
      "    FO: 7.5%\n",
      "    ÜB: 33.84%\n",
      "    SE: 7.53%\n",
      "    BE: 0.85%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 45.07%\n",
      "    SE: 15.56%\n",
      "    FO: 1.78%\n",
      "    AN: 6.78%\n",
      "    ÜB: 30.8%\n",
      "    BE: 0.01%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 1, 'SNS': 7, 'VIS': 5, 'GLO': 1}\n",
      "Total Nr. of LPs found for LS: 2\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.29%\n",
      "    AN: 14.29%\n",
      "    ZL: 14.29%\n",
      "    FO: 14.29%\n",
      "    ÜB: 14.29%\n",
      "    SE: 14.29%\n",
      "    RQ: 14.29%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 22.45%\n",
      "    FO: 22.45%\n",
      "    SE: 22.45%\n",
      "    RQ: 22.45%\n",
      "    AN: 10.19%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 50.0%\n",
      "    FO: 50.0%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'INT': 9, 'VIS': 9, 'GLO': 9}\n",
      "Total Nr. of LPs found for LS: 77\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    ZL: 24.25%\n",
      "    ÜB: 24.45%\n",
      "    FO: 24.45%\n",
      "    SE: 24.14%\n",
      "    AB: 0.86%\n",
      "    BE: 0.75%\n",
      "    AN: 0.71%\n",
      "    RQ: 0.39%\n",
      "    ZF: 0.0%\n",
      "    LK: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 34.37%\n",
      "    ÜB: 11.58%\n",
      "    FO: 17.69%\n",
      "    SE: 34.02%\n",
      "    AB: 0.41%\n",
      "    BE: 0.87%\n",
      "    RQ: 0.41%\n",
      "    AN: 0.65%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 48.4%\n",
      "    SE: 48.01%\n",
      "    AB: 0.36%\n",
      "    BE: 0.3%\n",
      "    FO: 1.21%\n",
      "    ÜB: 0.52%\n",
      "    RQ: 0.45%\n",
      "    AN: 0.76%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 1, 'SNS': 7, 'VIS': 5, 'SEQ': 5}\n",
      "Total Nr. of LPs found for LS: 49\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.29%\n",
      "    ZL: 14.29%\n",
      "    AN: 14.29%\n",
      "    FO: 14.29%\n",
      "    ÜB: 14.28%\n",
      "    SE: 14.29%\n",
      "    RQ: 14.29%\n",
      "    ZF: 0.01%\n",
      "    BE: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 22.49%\n",
      "    AN: 10.03%\n",
      "    FO: 22.49%\n",
      "    SE: 22.49%\n",
      "    RQ: 22.49%\n",
      "    ZF: 0.0%\n",
      "    ÜB: 0.0%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 24.99%\n",
      "    FO: 25.0%\n",
      "    SE: 25.0%\n",
      "    RQ: 25.0%\n",
      "    ZF: 0.01%\n",
      "    AN: 0.01%\n",
      "    ÜB: 0.0%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 3, 'SNS': 7, 'VIS': 3, 'GLO': 3}\n",
      "Total Nr. of LPs found for LS: 19\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 13.74%\n",
      "    AN: 13.74%\n",
      "    ZL: 13.74%\n",
      "    FO: 13.74%\n",
      "    ÜB: 13.74%\n",
      "    SE: 13.74%\n",
      "    RQ: 13.74%\n",
      "    BE: 3.84%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 21.34%\n",
      "    FO: 20.74%\n",
      "    ÜB: 21.34%\n",
      "    SE: 21.34%\n",
      "    AN: 11.59%\n",
      "    BE: 3.65%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 42.77%\n",
      "    SE: 34.66%\n",
      "    BE: 2.15%\n",
      "    FO: 6.62%\n",
      "    AN: 5.68%\n",
      "    ÜB: 8.12%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'REF': 3, 'SNS': 7, 'VIS': 5, 'GLO': 5}\n",
      "Total Nr. of LPs found for LS: 10\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    FO: 19.01%\n",
      "    ZL: 19.01%\n",
      "    AB: 10.87%\n",
      "    AN: 13.08%\n",
      "    ÜB: 15.02%\n",
      "    RQ: 19.01%\n",
      "    SE: 3.99%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    FO: 28.47%\n",
      "    ZL: 28.47%\n",
      "    AN: 10.42%\n",
      "    RQ: 22.88%\n",
      "    AB: 4.17%\n",
      "    SE: 5.59%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    FO: 70.81%\n",
      "    ZL: 29.19%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 5, 'SNS': 7, 'VIS': 7, 'GLO': 3}\n",
      "Total Nr. of LPs found for LS: 34\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.25%\n",
      "    ZL: 14.25%\n",
      "    AN: 14.25%\n",
      "    FO: 14.24%\n",
      "    ÜB: 13.66%\n",
      "    SE: 4.72%\n",
      "    RQ: 14.25%\n",
      "    BE: 10.38%\n",
      "    ZF: 0.0%\n",
      "    LK: 0.0%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 35.25%\n",
      "    AN: 15.03%\n",
      "    FO: 7.5%\n",
      "    ÜB: 33.84%\n",
      "    SE: 7.53%\n",
      "    BE: 0.85%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 45.07%\n",
      "    SE: 15.56%\n",
      "    FO: 1.78%\n",
      "    AN: 6.78%\n",
      "    ÜB: 30.8%\n",
      "    BE: 0.01%\n",
      "\n",
      "--------------------------------------------------------\n",
      "Analysis for Learning Style:\n",
      "{'AKT': 1, 'SNS': 7, 'VIS': 5, 'GLO': 1}\n",
      "Total Nr. of LPs found for LS: 2\n",
      "\n",
      "Problematic LEs, when no difference is allwoed (and percentage of error)\n",
      "    AB: 14.29%\n",
      "    AN: 14.29%\n",
      "    ZL: 14.29%\n",
      "    FO: 14.29%\n",
      "    ÜB: 14.29%\n",
      "    SE: 14.29%\n",
      "    RQ: 14.29%\n",
      "\n",
      "LPs with Difference +/-1 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 22.45%\n",
      "    FO: 22.45%\n",
      "    SE: 22.45%\n",
      "    RQ: 22.45%\n",
      "    AN: 10.19%\n",
      "\n",
      "LPs with Difference +/-2 allowed\n",
      "Accuracy: 0.0%\n",
      "Problematic LEs (and percentage of error)\n",
      "    ZL: 50.0%\n",
      "    FO: 50.0%\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Calculate the errors for GA\n",
    "for i in range(6):\n",
    "    error_calculation(i, 'GA')\n",
    "\n",
    "#Calculate the errors for ACO\n",
    "for i in range(6):\n",
    "    error_calculation(i, 'GA')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36acd0dee42c394d74b57d02f2f280be9661c2568943cc3a88809abc7536df25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
